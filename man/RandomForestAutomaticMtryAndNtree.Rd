% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/classification.R
\name{RandomForestAutomaticMtryAndNtree}
\alias{RandomForestAutomaticMtryAndNtree}
\title{Create random forest classification model after optimizing mtry and ntree}
\usage{
RandomForestAutomaticMtryAndNtree(
  inputted.data,
  name.of.predictors.to.use,
  target.column.name,
  seed
)
}
\arguments{
\item{inputted.data}{A dataframe.}

\item{name.of.predictors.to.use}{A vector of strings that specifies the columns with values that we want to use for prediction.}

\item{target.column.name}{A string that specifies the column with values that we want to predict for. This column should be a factor.}

\item{seed}{A integer that specifies the seed to use for random number generation.}
}
\value{
A randomForest object is returned
}
\description{
For this function, mtry is optimized using randomForest::tuneRF() and
ntree is optimized using find.best.number.of.trees() function on the out-of-bag
error. After optimizing for mtry and ntree, the optimal values are used
to create a new random forest model, and this model is outputted.
}
\details{
However, the default values of mtry and ntree from randomForest() are actually
preferred in most cases.
}
\examples{

id = c("1a", "1b", "1c", "1d", "1e", "1f", "1g", "2a", "2b", "2c", "2d", "2e", "2f", "3a",
       "3b", "3c", "3d", "3e", "3f", "3g", "3h", "3i")

x = c(18, 21, 22, 24, 26, 26, 27, 30, 31, 35, 39, 35, 30, 40, 41, 42, 44, 46, 47, 48, 49, 54)

y = c(10, 11, 22, 15, 12, 13, 14, 33, 39, 37, 44, 40, 45, 27, 29, 20, 28, 21, 30, 31, 23, 24)

a = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1)

b = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1)


actual = as.factor(c("1", "1", "1", "1", "1", "1", "1", "2", "2", "2", "2", "2",
       "2", "3", "3", "3",
       "3", "3", "3", "3", "3", "3"))

example.data <- data.frame(id, x, y, a, b, actual)

rf.result <- RandomForestAutomaticMtryAndNtree(example.data, c("x", "y", "a", "b"),
"actual", seed=2)

predicted <- rf.result$predicted
actual <- example.data[,"actual"]

#Result is not perfect because RF model does not over fit to the training data.
eval.classification.results(as.character(actual), as.character(predicted), "Example")

}
\seealso{
Other Classification functions: 
\code{\link{CVPredictionsRandomForest}()},
\code{\link{CVRandomForestClassificationMatrixForPheatmap}()},
\code{\link{GenerateExampleDataMachinelearnr}()},
\code{\link{LOOCVPredictionsRandomForestAutomaticMtryAndNtree}()},
\code{\link{LOOCVRandomForestClassificationMatrixForPheatmap}()},
\code{\link{RandomForestClassificationGiniMatrixForPheatmap}()},
\code{\link{RandomForestClassificationPercentileMatrixForPheatmap}()},
\code{\link{eval.classification.results}()},
\code{\link{find.best.number.of.trees}()}
}
\concept{Classification functions}
